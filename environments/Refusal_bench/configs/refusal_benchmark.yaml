# Environment configuration
env:
  group_size: 16
  tokenizer_name: "gpt2"
  use_wandb: true
  rollout_server_url: "https://inference-api.nousresearch.com/v1"  # Keep this for trainer communication
  rollout_model_name: "Hermes-3-Llama-3.1-70B"  # Add this field
  rollout_api_key: APIKEY  # Add this field
  wandb_name: "refusal_benchmark"
  total_steps: 500
  batch_size: 512
  max_token_length: 1024
  data_file: "hf_full_dataset.json"
  max_eval_samples: 4000
  classifier_type: "openai"
  eval_temperature: 0.7
  train_temperature: 0.8
  eval_max_tokens: 1024
  train_max_tokens: 1024
  use_label_0_for_training: true
  data_dir_to_save_evals: "results/refusal_evaluation"

# Server configurations - ONLY the classifier/judge
openai:
  - model_name: "Hermes-3-Llama-3.1-70B"  # Classifier model
    base_url: "https://inference-api.nousresearch.com/v1"
    api_key: APIKEY
    num_max_requests_at_once: 8
    num_requests_for_eval: 32
    server_type: "openai"
    timeout: 120
    weight: 1.0

slurm: false
testing: false
